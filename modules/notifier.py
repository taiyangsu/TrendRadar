# coding=utf-8

import json
import time
from typing import Dict, List, Tuple, Optional
import requests

from .config import load_config, VERSION
from .utils import get_beijing_time
from .report_generator import (
    render_feishu_content,
    render_dingtalk_content,
    format_title_for_platform,
    prepare_report_data
)
from .push_record import PushRecordManager


# åŠ è½½é…ç½®
CONFIG = load_config()


def split_content_into_batches(
    report_data: Dict,
    format_type: str,
    update_info: Optional[Dict] = None,
    max_bytes: int = CONFIG["MESSAGE_BATCH_SIZE"],
    mode: str = "daily",
) -> List[str]:
    """åˆ†æ‰¹å¤„ç†æ¶ˆæ¯å†…å®¹ï¼Œç¡®ä¿è¯ç»„æ ‡é¢˜+è‡³å°‘ç¬¬ä¸€æ¡æ–°é—»çš„å®Œæ•´æ€§"""
    batches = []

    total_titles = sum(
        len(stat["titles"]) for stat in report_data["stats"] if stat["count"] > 0
    )
    now = get_beijing_time()

    base_header = ""
    if format_type == "wework":
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n\n\n"
    elif format_type == "telegram":
        base_header = f"æ€»æ–°é—»æ•°ï¼š {total_titles}\n\n"

    base_footer = ""
    if format_type == "wework":
        base_footer = f"\n\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"
    elif format_type == "telegram":
        base_footer = f"\n\næ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\nTrendRadar å‘ç°æ–°ç‰ˆæœ¬ {update_info['remote_version']}ï¼Œå½“å‰ {update_info['current_version']}"

    stats_header = ""
    if report_data["stats"]:
        if format_type == "wework":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "telegram":
            stats_header = f"ğŸ“Š çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡\n\n"

    current_batch = base_header
    current_batch_has_content = False

    if (
        not report_data["stats"]
        and not report_data["new_titles"]
        and not report_data["failed_ids"]
    ):
        if mode == "incremental":
            mode_text = "å¢é‡æ¨¡å¼ä¸‹æš‚æ— æ–°å¢åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        elif mode == "current":
            mode_text = "å½“å‰æ¦œå•æ¨¡å¼ä¸‹æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        else:
            mode_text = "æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        simple_content = f"ğŸ“­ {mode_text}\n\n"
        final_content = base_header + simple_content + base_footer
        batches.append(final_content)
        return batches

    # å¤„ç†çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡
    if report_data["stats"]:
        total_count = len(report_data["stats"])

        # æ·»åŠ ç»Ÿè®¡æ ‡é¢˜
        test_content = current_batch + stats_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            < max_bytes
        ):
            current_batch = test_content
            current_batch_has_content = True
        else:
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + stats_header
            current_batch_has_content = True

        # é€ä¸ªå¤„ç†è¯ç»„ï¼ˆç¡®ä¿è¯ç»„æ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»çš„åŸå­æ€§ï¼‰
        for i, stat in enumerate(report_data["stats"]):
            word = stat["word"]
            count = stat["count"]
            sequence_display = f"[{i + 1}/{total_count}]"

            # æ„å»ºè¯ç»„æ ‡é¢˜
            word_header = ""
            if format_type == "wework":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
            elif format_type == "telegram":
                if count >= 10:
                    word_header = f"ğŸ”¥ {sequence_display} {word} : {count} æ¡\n\n"
                elif count >= 5:
                    word_header = f"ğŸ“ˆ {sequence_display} {word} : {count} æ¡\n\n"
                else:
                    word_header = f"ğŸ“Œ {sequence_display} {word} : {count} æ¡\n\n"

            # æ„å»ºç¬¬ä¸€æ¡æ–°é—»
            first_news_line = ""
            if stat["titles"]:
                first_title_data = stat["titles"][0]
                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", first_title_data, show_source=True
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", first_title_data, show_source=True
                    )
                else:
                    formatted_title = f"{first_title_data['title']}"

                first_news_line = f"  1. {formatted_title}\n"
                if len(stat["titles"]) > 1:
                    first_news_line += "\n"

            # åŸå­æ€§æ£€æŸ¥ï¼šè¯ç»„æ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»å¿…é¡»ä¸€èµ·å¤„ç†
            word_with_first_news = word_header + first_news_line
            test_content = current_batch + word_with_first_news

            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                # å½“å‰æ‰¹æ¬¡å®¹çº³ä¸ä¸‹ï¼Œå¼€å¯æ–°æ‰¹æ¬¡
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + stats_header + word_with_first_news
                current_batch_has_content = True
                start_index = 1
            else:
                current_batch = test_content
                current_batch_has_content = True
                start_index = 1

            # å¤„ç†å‰©ä½™æ–°é—»æ¡ç›®
            for j in range(start_index, len(stat["titles"])):
                title_data = stat["titles"][j]
                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", title_data, show_source=True
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data, show_source=True
                    )
                else:
                    formatted_title = f"{title_data['title']}"

                news_line = f"  {j + 1}. {formatted_title}\n"
                if j < len(stat["titles"]) - 1:
                    news_line += "\n"

                test_content = current_batch + news_line
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    >= max_bytes
                ):
                    if current_batch_has_content:
                        batches.append(current_batch + base_footer)
                    current_batch = base_header + stats_header + word_header + news_line
                    current_batch_has_content = True
                else:
                    current_batch = test_content
                    current_batch_has_content = True

            # è¯ç»„é—´åˆ†éš”ç¬¦
            if i < len(report_data["stats"]) - 1:
                separator = ""
                if format_type == "wework":
                    separator = f"\n\n\n\n"
                elif format_type == "telegram":
                    separator = f"\n\n"

                test_content = current_batch + separator
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    < max_bytes
                ):
                    current_batch = test_content

    # å¤„ç†æ–°å¢æ–°é—»ï¼ˆåŒæ ·ç¡®ä¿æ¥æºæ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»çš„åŸå­æ€§ï¼‰
    if report_data["new_titles"]:
        new_header = ""
        if format_type == "wework":
            new_header = f"\n\n\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "telegram":
            new_header = (
                f"\n\nğŸ†• æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—» (å…± {report_data['total_new_count']} æ¡)\n\n"
            )

        test_content = current_batch + new_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            >= max_bytes
        ):
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + new_header
            current_batch_has_content = True
        else:
            current_batch = test_content
            current_batch_has_content = True

        # é€ä¸ªå¤„ç†æ–°å¢æ–°é—»æ¥æº
        for source_data in report_data["new_titles"]:
            source_header = ""
            if format_type == "wework":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "telegram":
                source_header = f"{source_data['source_name']} ({len(source_data['titles'])} æ¡):\n\n"

            # æ„å»ºç¬¬ä¸€æ¡æ–°å¢æ–°é—»
            first_news_line = ""
            if source_data["titles"]:
                first_title_data = source_data["titles"][0]
                title_data_copy = first_title_data.copy()
                title_data_copy["is_new"] = False

                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", title_data_copy, show_source=False
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data_copy, show_source=False
                    )
                else:
                    formatted_title = f"{title_data_copy['title']}"

                first_news_line = f"  1. {formatted_title}\n"

            # åŸå­æ€§æ£€æŸ¥ï¼šæ¥æºæ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»
            source_with_first_news = source_header + first_news_line
            test_content = current_batch + source_with_first_news

            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + new_header + source_with_first_news
                current_batch_has_content = True
                start_index = 1
            else:
                current_batch = test_content
                current_batch_has_content = True
                start_index = 1

            # å¤„ç†å‰©ä½™æ–°å¢æ–°é—»
            for j in range(start_index, len(source_data["titles"])):
                title_data = source_data["titles"][j]
                title_data_copy = title_data.copy()
                title_data_copy["is_new"] = False

                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", title_data_copy, show_source=False
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data_copy, show_source=False
                    )
                else:
                    formatted_title = f"{title_data_copy['title']}"

                news_line = f"  {j + 1}. {formatted_title}\n"

                test_content = current_batch + news_line
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    >= max_bytes
                ):
                    if current_batch_has_content:
                        batches.append(current_batch + base_footer)
                    current_batch = base_header + new_header + source_header + news_line
                    current_batch_has_content = True
                else:
                    current_batch = test_content
                    current_batch_has_content = True

            current_batch += "\n"

    if report_data["failed_ids"]:
        failed_header = ""
        if format_type == "wework":
            failed_header = f"\n\n\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "telegram":
            failed_header = f"\n\nâš ï¸ æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š\n\n"

        test_content = current_batch + failed_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            >= max_bytes
        ):
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + failed_header
            current_batch_has_content = True
        else:
            current_batch = test_content
            current_batch_has_content = True

        for i, id_value in enumerate(report_data["failed_ids"], 1):
            failed_line = f"  â€¢ {id_value}\n"
            test_content = current_batch + failed_line
            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + failed_header + failed_line
                current_batch_has_content = True
            else:
                current_batch = test_content
                current_batch_has_content = True

    # å®Œæˆæœ€åæ‰¹æ¬¡
    if current_batch_has_content:
        batches.append(current_batch + base_footer)

    return batches


def send_to_webhooks(
    stats: List[Dict],
    failed_ids: Optional[List] = None,
    report_type: str = "å½“æ—¥æ±‡æ€»",
    new_titles: Optional[Dict] = None,
    id_to_name: Optional[Dict] = None,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> Dict[str, bool]:
    """å‘é€æ•°æ®åˆ°å¤šä¸ªwebhookå¹³å°"""
    results = {}

    if CONFIG["SILENT_PUSH"]["ENABLED"]:
        push_manager = PushRecordManager()
        time_range_start = CONFIG["SILENT_PUSH"]["TIME_RANGE"]["START"]
        time_range_end = CONFIG["SILENT_PUSH"]["TIME_RANGE"]["END"]
        
        if not push_manager.is_in_time_range(time_range_start, time_range_end):
            now = get_beijing_time()
            print(f"é™é»˜æ¨¡å¼ï¼šå½“å‰æ—¶é—´ {now.strftime('%H:%M')} ä¸åœ¨æ¨é€æ—¶é—´èŒƒå›´ {time_range_start}-{time_range_end} å†…ï¼Œè·³è¿‡æ¨é€")
            return results
        
        if CONFIG["SILENT_PUSH"]["ONCE_PER_DAY"]:
            if push_manager.has_pushed_today():
                print(f"é™é»˜æ¨¡å¼ï¼šä»Šå¤©å·²æ¨é€è¿‡ï¼Œè·³è¿‡æœ¬æ¬¡æ¨é€")
                return results
            else:
                print(f"é™é»˜æ¨¡å¼ï¼šä»Šå¤©é¦–æ¬¡æ¨é€")
    
    report_data = prepare_report_data(stats, failed_ids, new_titles, id_to_name, mode)

    feishu_url = CONFIG["FEISHU_WEBHOOK_URL"]
    dingtalk_url = CONFIG["DINGTALK_WEBHOOK_URL"]
    wework_url = CONFIG["WEWORK_WEBHOOK_URL"]
    telegram_token = CONFIG["TELEGRAM_BOT_TOKEN"]
    telegram_chat_id = CONFIG["TELEGRAM_CHAT_ID"]

    update_info_to_send = update_info if CONFIG["SHOW_VERSION_UPDATE"] else None

    # å‘é€åˆ°é£ä¹¦
    if feishu_url:
        results["feishu"] = send_to_feishu(
            feishu_url, report_data, report_type, update_info_to_send, proxy_url, mode
        )

    # å‘é€åˆ°é’‰é’‰
    if dingtalk_url:
        results["dingtalk"] = send_to_dingtalk(
            dingtalk_url, report_data, report_type, update_info_to_send, proxy_url, mode
        )

    # å‘é€åˆ°ä¼ä¸šå¾®ä¿¡
    if wework_url:
        results["wework"] = send_to_wework(
            wework_url, report_data, report_type, update_info_to_send, proxy_url, mode
        )

    # å‘é€åˆ° Telegram
    if telegram_token and telegram_chat_id:
        results["telegram"] = send_to_telegram(
            telegram_token,
            telegram_chat_id,
            report_data,
            report_type,
            update_info_to_send,
            proxy_url,
            mode,
        )

    if not results:
        print("æœªé…ç½®ä»»ä½•webhook URLï¼Œè·³è¿‡é€šçŸ¥å‘é€")

    # å¦‚æœæˆåŠŸå‘é€äº†ä»»ä½•é€šçŸ¥ï¼Œä¸”å¯ç”¨äº†æ¯å¤©åªæ¨ä¸€æ¬¡ï¼Œåˆ™è®°å½•æ¨é€
    if CONFIG["SILENT_PUSH"]["ENABLED"] and CONFIG["SILENT_PUSH"]["ONCE_PER_DAY"] and any(results.values()):
        push_manager = PushRecordManager()
        push_manager.record_push(report_type)
        
    return results


def send_to_feishu(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°é£ä¹¦"""
    headers = {"Content-Type": "application/json"}

    text_content = render_feishu_content(report_data, update_info, mode)
    total_titles = sum(
        len(stat["titles"]) for stat in report_data["stats"] if stat["count"] > 0
    )

    now = get_beijing_time()
    payload = {
        "msg_type": "text",
        "content": {
            "total_titles": total_titles,
            "timestamp": now.strftime("%Y-%m-%d %H:%M:%S"),
            "report_type": report_type,
            "text": text_content,
        },
    }

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    try:
        response = requests.post(
            webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
        )
        if response.status_code == 200:
            print(f"é£ä¹¦é€šçŸ¥å‘é€æˆåŠŸ [{report_type}]")
            return True
        else:
            print(f"é£ä¹¦é€šçŸ¥å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
            return False
    except Exception as e:
        print(f"é£ä¹¦é€šçŸ¥å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
        return False


def send_to_dingtalk(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°é’‰é’‰"""
    headers = {"Content-Type": "application/json"}

    text_content = render_dingtalk_content(report_data, update_info, mode)

    payload = {
        "msgtype": "markdown",
        "markdown": {
            "title": f"TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š - {report_type}",
            "text": text_content,
        },
    }

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    try:
        response = requests.post(
            webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
        )
        if response.status_code == 200:
            result = response.json()
            if result.get("errcode") == 0:
                print(f"é’‰é’‰é€šçŸ¥å‘é€æˆåŠŸ [{report_type}]")
                return True
            else:
                print(f"é’‰é’‰é€šçŸ¥å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('errmsg')}")
                return False
        else:
            print(f"é’‰é’‰é€šçŸ¥å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
            return False
    except Exception as e:
        print(f"é’‰é’‰é€šçŸ¥å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
        return False


def send_to_wework(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰"""
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–åˆ†æ‰¹å†…å®¹
    batches = split_content_into_batches(report_data, "wework", update_info, mode=mode)

    print(f"ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ·»åŠ æ‰¹æ¬¡æ ‡è¯†
        if len(batches) > 1:
            batch_header = f"**[ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡]**\n\n"
            batch_content = batch_header + batch_content

        payload = {"msgtype": "markdown", "markdown": {"content": batch_content}}

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("errcode") == 0:
                    print(f"ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('errmsg')}"
                    )
                    return False
            else:
                print(
                    f"ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"ä¼ä¸šå¾®ä¿¡æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_telegram(
    bot_token: str,
    chat_id: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°Telegramï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰"""
    headers = {"Content-Type": "application/json"}
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–åˆ†æ‰¹å†…å®¹
    batches = split_content_into_batches(
        report_data, "telegram", update_info, mode=mode
    )

    print(f"Telegramæ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ·»åŠ æ‰¹æ¬¡æ ‡è¯†
        if len(batches) > 1:
            batch_header = f"<b>[ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡]</b>\n\n"
            batch_content = batch_header + batch_content

        payload = {
            "chat_id": chat_id,
            "text": batch_content,
            "parse_mode": "HTML",
            "disable_web_page_preview": True,
        }

        try:
            response = requests.post(
                url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("ok"):
                    print(f"Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('description')}"
                    )
                    return False
            else:
                print(
                    f"Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"Telegramæ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True